"""
ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã®ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™:
- Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æ
- ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒ£ãƒ³ã‚¯åŒ–
- FTPã¨ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
- sqlite-vecãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã¨æ§‹ç¯‰
"""

import os
import glob
import yaml
import sqlite3
import sqlite_vec
import tempfile
from typing import List, Dict, Tuple, Iterator
from ftplib import FTP, error_perm
from tqdm import tqdm

from .vector_utils import (
    EmbeddingModelManager, 
    SqliteVecDatabase, 
    ConfigManager,
    SQLITE_DB_PATH,
    EMBEDDING_DIMENSION
)


class MarkdownParser:
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def parse_markdown_with_url(filepath: str) -> Tuple[str, str]:
        """
        Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦URLã¨æœ¬æ–‡ã‚’å–å¾—ã™ã‚‹
        
        Args:
            filepath: Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            (url, body): URLã¨æœ¬æ–‡ã®ã‚¿ãƒ—ãƒ«
        """
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
        
        if content.startswith("---"):
            end = content.find("---", 3)
            if end != -1:
                header = content[3:end]
                body = content[end+3:].strip()
                try:
                    meta = yaml.safe_load(header)
                    url = meta.get("url", "") if meta else ""
                    return url, body
                except yaml.YAMLError:
                    pass
        
        return "", content


class TextChunker:
    """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒ£ãƒ³ã‚¯åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, chunk_size: int = 500):
        self.chunk_size = chunk_size
    
    def chunk_text(self, text: str) -> List[str]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šã•ã‚ŒãŸã‚µã‚¤ã‚ºã§ãƒãƒ£ãƒ³ã‚¯åŒ–ã™ã‚‹
        
        Args:
            text: ãƒãƒ£ãƒ³ã‚¯åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            ãƒãƒ£ãƒ³ã‚¯åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        import re
        
        sentences = re.split(r"(?<=[ã€‚ï¼ï¼ï¼Ÿ!?\n])", text)
        chunks = []
        current = ""
        
        for sentence in sentences:
            if len(current) + len(sentence) > self.chunk_size and current:
                chunks.append(current.strip())
                current = sentence
            else:
                current += sentence
        
        if current.strip():
            chunks.append(current.strip())
        
        return [chunk for chunk in chunks if chunk]


class FTPDataSource:
    """FTPãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, host: str, user: str = "anonymous", password: str = ""):
        self.host = host
        self.user = user
        self.password = password
    
    def list_md_files(self, path: str) -> List[str]:
        """FTPã‚µãƒ¼ãƒãƒ¼ä¸Šã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«å–å¾—ã™ã‚‹"""
        md_files = []
        
        with FTP(self.host) as ftp:
            ftp.login(user=self.user, passwd=self.password)
            md_files = self._list_md_files_recursive(ftp, path)
        
        return md_files
    
    def _list_md_files_recursive(self, ftp: FTP, path: str) -> List[str]:
        """FTPã‚µãƒ¼ãƒãƒ¼ä¸Šã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«å–å¾—ã™ã‚‹ï¼ˆå†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        md_files = []
        
        try:
            ftp.cwd(path)
            items = ftp.nlst()
        except error_perm:
            return []
        
        for item in items:
            if item in ('.', '..'):
                continue
            
            sub_path = path.rstrip('/') + '/' + item
            
            try:
                ftp.cwd(sub_path)
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã‚‰å†å¸°
                md_files.extend(self._list_md_files_recursive(ftp, sub_path))
                ftp.cwd('..')
            except error_perm:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãªã‚‰æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
                if item.lower().endswith('.md'):
                    md_files.append(sub_path)
        
        return md_files
    
    def download_file(self, remote_path: str, local_path: str):
        """FTPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
        with FTP(self.host) as ftp:
            ftp.login(user=self.user, passwd=self.password)
            with open(local_path, 'wb') as f:
                ftp.retrbinary(f"RETR {remote_path}", f.write)
    
    def get_markdown_files(self, data_dir: str) -> Iterator[Tuple[str, str, str]]:
        """
        FTPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã™ã‚‹
        
        Yields:
            (url, body, filename): URLã€æœ¬æ–‡ã€ãƒ•ã‚¡ã‚¤ãƒ«åã®ã‚¿ãƒ—ãƒ«
        """
        md_files = self.list_md_files(data_dir)
        print(f"ğŸ“ FTPã‹ã‚‰{len(md_files)}å€‹ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")
        
        with tempfile.TemporaryDirectory() as tmpdir:
            for remote_path in md_files:
                local_path = os.path.join(tmpdir, os.path.basename(remote_path))
                self.download_file(remote_path, local_path)
                
                url, body = MarkdownParser.parse_markdown_with_url(local_path)
                filename = os.path.basename(remote_path)
                
                yield url, body, filename


class LocalDataSource:
    """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, directory: str):
        self.directory = directory
    
    def list_md_files(self) -> List[str]:
        """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé…ä¸‹ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«å–å¾—ã™ã‚‹"""
        md_files = []
        
        if not os.path.exists(self.directory):
            print(f"âš ï¸  ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {self.directory}")
            return md_files
        
        for root, dirs, files in os.walk(self.directory):
            for file in files:
                if file.lower().endswith('.md'):
                    md_files.append(os.path.join(root, file))
        
        return md_files
    
    def get_markdown_files(self) -> Iterator[Tuple[str, str, str]]:
        """
        ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã™ã‚‹
        
        Yields:
            (url, body, filename): URLã€æœ¬æ–‡ã€ãƒ•ã‚¡ã‚¤ãƒ«åã®ã‚¿ãƒ—ãƒ«
        """
        md_files = self.list_md_files()
        print(f"ğŸ“ ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰{len(md_files)}å€‹ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")
        
        for file_path in md_files:
            try:
                url, body = MarkdownParser.parse_markdown_with_url(file_path)
                filename = os.path.basename(file_path)
                yield url, body, filename
            except Exception as e:
                print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({file_path}): {e}")
                continue


class DatabaseBuilder:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: str = SQLITE_DB_PATH):
        self.db_path = db_path
        self.model_manager = EmbeddingModelManager()
        self.chunker = TextChunker()
    
    def initialize_database(self) -> sqlite3.Connection:
        """sqlite-vecãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹"""
        # æ—¢å­˜ã®DBãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
        if os.path.exists(self.db_path):
            os.remove(self.db_path)
        
        # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶š
        conn = sqlite3.connect(self.db_path)
        
        # æ‹¡å¼µæ©Ÿèƒ½ã®èª­ã¿è¾¼ã¿ã‚’æœ‰åŠ¹åŒ–
        conn.enable_load_extension(True)
        
        # sqlite-vecæ‹¡å¼µã‚’èª­ã¿è¾¼ã¿
        sqlite_vec.load(conn)
        
        # æ‹¡å¼µæ©Ÿèƒ½ã®èª­ã¿è¾¼ã¿ã‚’ç„¡åŠ¹åŒ–ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ï¼‰
        conn.enable_load_extension(False)
        
        # vec0ä»®æƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
        conn.execute(f"""
            CREATE VIRTUAL TABLE docs USING vec0(
                embedding float[{EMBEDDING_DIMENSION}],
                chunk_text TEXT,
                url TEXT,
                file_name TEXT,
                source TEXT
            )
        """)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚‚ä½œæˆ
        conn.execute("""
            CREATE TABLE doc_metadata (
                id INTEGER PRIMARY KEY,
                url TEXT,
                file_name TEXT,
                source TEXT,
                chunk_text TEXT
            )
        """)
        
        conn.commit()
        return conn
    
    def build_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹"""
        config = ConfigManager.get_data_source_config()
        
        print("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š:")
        print(f"  ä½¿ç”¨ã™ã‚‹ã‚½ãƒ¼ã‚¹: {'FTP' if config['use_ftp_source'] else 'ãƒ­ãƒ¼ã‚«ãƒ«'}")
        
        if config['use_ftp_source']:
            print(f"  FTPãƒ›ã‚¹ãƒˆ: {config['ftp_host']}")
            print(f"  FTPãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {config['ftp_data_dir']}")
            data_source = FTPDataSource(
                config['ftp_host'], 
                config['ftp_user'], 
                config['ftp_pass']
            )
            markdown_files = data_source.get_markdown_files(config['ftp_data_dir'])
            source_type = "ftp"
        else:
            print(f"  ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {config['local_dir']}")
            data_source = LocalDataSource(config['local_dir'])
            markdown_files = data_source.get_markdown_files()
            source_type = "local"
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–
        conn = self.initialize_database()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
        texts = []
        metadatas = []
        
        try:
            for url, body, filename in markdown_files:
                chunks = self.chunker.chunk_text(body)
                for chunk in chunks:
                    texts.append(chunk)
                    metadatas.append({
                        "url": url,
                        "file_name": filename,
                        "source": source_type
                    })
        except Exception as e:
            print(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            conn.close()
            return
        
        if not texts:
            print("âš ï¸  å‡¦ç†ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            conn.close()
            return
        
        print(f"ğŸ”„ {len(texts)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆä¸­...")
        
        # ãƒãƒƒãƒå‡¦ç†ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥
        for i, (text, metadata) in enumerate(tqdm(
            zip(texts, metadatas),
            total=len(texts),
            desc="åŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ»æŒ¿å…¥",
            unit="ãƒãƒ£ãƒ³ã‚¯",
            ncols=80
        )):
            # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
            embedding = self.model_manager.get_embedding(text)
            
            # sqlite-vecã®serialize_float32ã‚’ä½¿ç”¨ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º
            embedding_blob = sqlite_vec.serialize_float32(embedding)
            
            # vec0ä»®æƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥
            conn.execute("""
                INSERT INTO docs (embedding, chunk_text, url, file_name, source)
                VALUES (?, ?, ?, ?, ?)
            """, (
                embedding_blob, 
                text, 
                metadata["url"], 
                metadata["file_name"], 
                metadata["source"]
            ))
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚‚æŒ¿å…¥
            conn.execute("""
                INSERT INTO doc_metadata (url, file_name, source, chunk_text)
                VALUES (?, ?, ?, ?)
            """, (
                metadata["url"], 
                metadata["file_name"], 
                metadata["source"], 
                text
            ))
        
        conn.commit()
        conn.close()
        print(f"âœ… sqlite-vecæ§‹ç¯‰å®Œäº†: {len(texts)}ä»¶ã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")